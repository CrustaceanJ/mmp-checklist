# mmp-checklist
Notes about work and list of articles I read

Список статей, которые прочитаны или будут прочитаны (черновик): <s>https://docs.google.com/spreadsheets/d/194xzdxKKLoknptjXv88w5oI7mEvFz1lNCsqk6hLNI6Q/edit?usp=sharing</s>
* * *
**02.09.2019**. Начало.

**21.09.2019**. Просмотрел лекции по генетике (https://zagadkigenoma.ru/zaghadki_ghienoma)

**25.11.2019**. https://towardsdatascience.com/the-hitchhikers-guide-to-feature-extraction-b4c157e96631. Как на практике автоматически выделять фичи (немного про featuretools). Интересный hint при работе с метрическими данными на карте - haversine distance. https://habr.com/ru/post/428213/ - про SHAP. http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf - примемущества Random Search над GridSearch (надо расшарить смеси гассовских распределений)

* * *
**3 Курс 2 семестр**

**15.02.2020**. Начал рекурсивно просматривать статьи из https://github.com/WillKoehrsen/hyperparameter-optimization/blob/master/Introduction%20to%20Bayesian%20Optimization%20with%20Hyperopt.ipynb. На данный момент требуется в срочном порядке пройти курсы по БММО.

**07.02.2020**. Перенёс заметки из Trello.

Интересный набор статей:
https://github.com/Sahaj09/Reading-List-Hyperparameter-Optimization/

Крутая обзорная статья, в ней описаны основные подходы к Байесовской оптимизации (Bandit-Based, GLM (это скорее в качестве подводки к GP), GP. Рассмотренны различные варианты выбора acquisition function: PI, EI, UCB, ES, PES, Portfolios of Acquisition Function. Также приведены способы ускорения работы гауссовского процесса, поскольку vanila-GP работает за O(N^3). Там предлагают метод вспомогательных точек и спектральные методы)

Обзорная статья скорее всеобъемлющая:
https://arxiv.org/pdf/2003.05689.pdf

Супер крутая книжка, где есть выводы для гауссовского процесса:
http://www.gaussianprocess.org/gpml/chapters/RW.pdf

Более эффективный RS:
https://arxiv.org/abs/2004.01628



